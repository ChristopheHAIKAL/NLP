# NLP
This repo is a part of Advanced Machine Learning for Big Data and Text Processing course at [ESILV-Paris](https://www.esilv.fr/en/). 

#### -- Project Status: [Completed]

## Project1
The goal of the project is to provide a data text synthesis of a massive corpora of scientific articles
about natural language processing.
This amount of data is not really big, just 44Mo, but is big enough to be too complicated to be
processed by hand.


## Project2
The goal of the project is to provide a model able to predict for a given scientific article on NLP the
year of publication. We use the same data as the first project but in a supervised way.
You are in charge to split the data in train/test/validation sets with 80/10/10 respectively for
example. You can evaluate your model with a MSE error, since making a mistake of ten years or
one year it’s not as important.
The goal is not to reach the highest score. It’s easy, you can train on all the datas and generate a
model that is just a memory and achieve a perfect model, which is not very interesting.
Two mains expectations of the project :
1) propose a model to achieve this goal and explain all your modifications step by step, in
order to improve your result. You can use different models, but you need at least show the evolution
of one model.
2) You need to analyse the results : Which years are more difficults ? Why ? Which articles
are more difficult, or which key-words are considered more difficults ?
Answering to this questions is an other way to synthetise the corpus and understand the evolution of
Natural Language Processing.


### Methods Used
* Inferential Statistics
* Machine Learning
* Data Visualization
* Predictive Modeling


### Technologies
* Python
* Pandas, jupyter
* Django


#### Contact

|Name     | 
|---------|
|[Christophe Haikal](https://github.com/ChristopheHAIKAL)|
|[Ryan Jebali](https://github.com/hug0prevoteau) |   
